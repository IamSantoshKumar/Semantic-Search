{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e613b502",
   "metadata": {},
   "source": [
    "# Semantic Search (Sentence Transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6593cc30",
   "metadata": {},
   "source": [
    "In natural language processing (NLP), semantic search refers to the ability of a search engine to understand the intent behind a user's query, and to return results that are semantically related to the user's search terms. This is in contrast to a keyword-based search, which returns results based on the exact words that the user entered, regardless of their intended meaning. Semantic search is typically based on natural language processing techniques such as word sense disambiguation and part-of-speech tagging, which allow the search engine to understand the meaning of the words in a query and to identify semantically related terms. This can help to improve the accuracy and relevance of search results, and can make it easier for users to find the information they are looking for.\n",
    "\n",
    "courtesy: chatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "56f85520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import functools\n",
    "from typing import Tuple, List\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9467e3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] \n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9ff5ef05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Sentence-Transformers is a library for natural language processing (NLP) that provides state-of-the-art sentence embedding models. \n",
    "These models are trained using a technique called BERT, which stands for \"Bidirectional Encoder Representations from Transformers.\"\n",
    "BERT is a type of transformer model that uses attention mechanisms to learn contextual relationships between words in a sentence. \n",
    "The resulting sentence embeddings can be used for a wide range of downstream NLP tasks, such as text classification, information retrieval, and semantic search. \n",
    "The Sentence-Transformers library makes it easy to use these models in your own NLP projects,\n",
    "and includes a variety of pre-trained models that can be fine-tuned on specific tasks or datasets.\n",
    "\"\"\"\n",
    "\n",
    "MODEL_NAME = 'sentence-transformers/all-mpnet-base-v2'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModel.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "7829fe40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(query: List=[], corpus: List=[], top_k=5) -> List:\n",
    "    \n",
    "    #tokenize the sentences\n",
    "    corpus_input = tokenizer(corpus, padding=True, truncation=True, return_tensors='pt')\n",
    "    query_input = tokenizer(query, padding=True, truncation=True, return_tensors='pt')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        corpus_output = model(**corpus_input)\n",
    "        query_output = model(**query_input)\n",
    "      \n",
    "    #Mean pool on output embeddings\n",
    "    corpus_embeddings = mean_pooling(model_output, corpus_input['attention_mask'])\n",
    "    query_embeddings = mean_pooling(query_output, query_input['attention_mask'])\n",
    "     \n",
    "    #Normalize the embeddings\n",
    "    corpus_embeddings = F.normalize(corpus_embeddings, p=2, dim=1)\n",
    "    query_embeddings = F.normalize(query_embeddings, p=2, dim=1)\n",
    "\n",
    "    corpus_embeddings = corpus_embeddings.detach().cpu().numpy()\n",
    "    query_embeddings = query_embeddings.detach().cpu().numpy()\n",
    "\n",
    "    #Calculate the cosine similarity between embeddings\n",
    "    sim = cosine_similarity(query_embeddings, corpus_embeddings)[0]\n",
    "\n",
    "    sorted_index = list(np.argsort(-sim)+1)\n",
    "\n",
    "    score = list(sim[np.argsort(-sim)])\n",
    "    \n",
    "    similar_sentences = [(corpus[idx-1], score) for idx, score in zip(sort_idx[:top_k], score[:top_k])]\n",
    "    \n",
    "    return similar_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "bb042c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['The cat sits outside',\n",
    "             'A man is playing guitar',\n",
    "             'I love pasta',\n",
    "             'The new movie is awesome',\n",
    "             'The cat plays in the garden',\n",
    "             'A woman watches TV',\n",
    "             'The new movie is so great',\n",
    "             'Do you like pizza?']\n",
    "\n",
    "\n",
    "query = ['The cat plays in the garden',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "c820141f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The cat plays in the garden', 1.0000001),\n",
       " ('The cat sits outside', 0.6738439),\n",
       " ('I love pasta', 0.11078529),\n",
       " ('Do you like pizza?', 0.09111777)]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Top 5 Similar Sentences\n",
    "semantic_search(query, corpus, top_k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f82644",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
